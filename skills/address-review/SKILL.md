---
name: address-review
description: Address feedback from code review with automated fixes
allowed-tools: Task
argument-hint: "[review-doc or slug] [--priority=high|medium|low|all]"
---

# Address Review Skill

This skill reads code review documents generated by `/review` or
`/review-implementation` and applies automated fixes for identified issues.
It focuses on safe, straightforward fixes while flagging complex issues for
manual intervention.

## Instructions

Spawn a general-purpose agent via Task with this prompt:

```
Address feedback from a code review document.

## Parse Arguments

Parse $ARGUMENTS for:
- `--priority=LEVEL` flag: Filter issues by priority (high|medium|low|all)
  - Default: high (only address high priority issues)
  - medium: address high and medium priority issues
  - low: address high, medium, and low priority issues
  - all: address all issues regardless of priority
- Review doc path or slug: remaining arguments after flags

## Find Review Document

If argument provided (excluding flags):
- If ends with .md: use as direct path to review document
- Otherwise: treat as slug and find most recent matching file:
  - .jim/notes/review-impl-*{slug}*.md
  - .jim/notes/review-*{slug}*.md

If no arguments provided:
- Find most recent review document in .jim/notes/
- Prefer review-impl-* over review-* (implementation reviews first)

Read the review document to verify it exists and is well-formed.

## Parse Review Feedback

Extract actionable recommendations from review document:

### 1. Parse Recommendations Table

Find "## Recommendations" section and parse table:

```markdown
| Priority | Item | Action |
|----------|------|--------|
| High | {issue} | {what to do} |
```

Extract:
- Priority level (High, Medium, Low)
- Item description
- Action to take

**Parsing tips:**
- Table rows may use different separators (spaces, tabs)
- Priority values are case-insensitive (High, high, HIGH)
- Some recommendations may reference files, extract those paths
- Action column contains the specific task to perform
- If Action says "Verify" or "Consider whether": these are optional
  suggestions, not required fixes

### 2. Parse Areas for Improvement

Find "## Areas for Improvement" section and extract subsections:

```markdown
### Code Quality

**File: /absolute/path/to/file.ext:23**

Description of issue.

Here's why this matters: explanation.

Consider: suggestion for fix.

To fix:
1. Step one
2. Step two
```

Extract:
- Category (Architecture, Code Quality, Standards, Security/Performance)
- File path from "**File: ...**" markers
- Line numbers if provided (e.g., ":23")
- Issue description
- Suggested fix from "Consider:" or "To fix:" sections
- Code examples if provided

### 3. Cross-reference with Files Changed

If review document has "Files Reviewed" or mentions specific files:
- Prioritize fixes in files that actually exist
- Skip fixes for files not in current working directory

## Filter by Priority Level

Based on --priority flag (default: high):

- `--priority=high`: Only High priority items
- `--priority=medium`: High and Medium priority items
- `--priority=low`: High, Medium, and Low priority items
- `--priority=all`: All items regardless of priority level

Create filtered list of issues to address.

**Important:** If no issues match the priority filter (e.g., review only has
Low priority items and user ran with default --priority=high), report this
to the user clearly:

```
No issues found matching priority level: high

The review contains:
  - 0 High priority issues
  - 0 Medium priority issues
  - 3 Low priority issues

To address all issues, run: /address-review --priority=all
```

Exit gracefully if no issues to address.

## Categorize Fixes

Classify each issue as:

**Simple fixes (can automate):**
- Variable/function renaming
- Comment removal or improvement
- Constant extraction
- Import additions/removals
- Simple formatting issues
- Basic refactoring (extract variable, inline variable)
- Removing unused code
- Adding missing null checks
- Documentation additions (adding parenthetical clarifications)
- Argument hint enhancements
- Simple sentence additions to existing sections

**Complex fixes (require manual intervention):**
- Architecture changes
- Logic modifications
- Algorithm improvements
- Error handling additions requiring business logic
- Security vulnerability fixes (need careful review)
- Performance optimizations requiring profiling
- Breaking API changes
- Cross-file audits or validations
- Changes requiring understanding of system state

**Edge cases to handle:**
- If suggestion says "consider" or "would be worth": treat as optional,
  categorize based on complexity
- If suggestion has multiple steps: evaluate each step's complexity
- If file path is missing or ambiguous: skip and note in summary
- If line number is outdated (code changed): skip or search by pattern
- If review says "verify" or "audit": skip (requires human judgment)

For complex fixes: add to "Issues Requiring Manual Intervention" list.

## Create Task List

For each simple fix:
- TaskCreate with clear subject and description
- Include file path, line number, issue, and suggested fix
- Group tasks by file for efficient processing
- activeForm: "Applying {fix type} to {filename}"

For complex fixes:
- Create informational tasks (don't mark as actionable)
- Note: "Requires manual intervention"

## Apply Fixes

For each simple fix task:

1. **TaskUpdate to in_progress**

2. **Read entire file for context**
   - Understand file structure
   - Locate issue by line number or code pattern
   - Verify issue still exists (might already be fixed)

3. **Apply suggested fix using Edit tool**
   - Follow suggestion from review document exactly
   - Use old_string/new_string with sufficient context
   - Preserve code intent and behavior
   - Maintain existing code style

4. **Verify syntax after edit**
   - Check file can be parsed (basic syntax check)
   - Don't run full tests (user will do that)
   - If syntax broken: revert change, mark task as failed

5. **TaskUpdate to completed**
   - If fix succeeded: mark completed
   - If fix failed: mark as failed, note reason, continue

6. **Error handling**
   - If file not found: skip, note in summary
   - If Edit fails: try more specific context, or skip
   - If ambiguous suggestion: skip, note as "requires manual review"

## Track Results

Maintain counts:
- Issues addressed successfully
- Issues skipped (low priority, complex, ambiguous)
- Issues failed (couldn't apply fix)
- Files modified

Group results by file for summary.

## Generate Fixes Summary Document

Create summary at .jim/notes/fixes-{timestamp}-{slug}.md:

```markdown
# Review Fixes Applied: {topic from review}

Applied: {ISO timestamp, e.g., 2026-01-30T22:30:00Z}
Review Source: {absolute path to review document}
Priority Level: {high|medium|low}

## Summary

Total Issues in Review: {count}
Issues Addressed: {count} ({percentage}%)
Issues Skipped: {count}
Issues Failed: {count}

## Issues Addressed

{Group by file}

### /absolute/path/to/file.ext

- [x] **{Issue from review}**
  - Line: {line number if available}
  - Fix: {brief description of what was done}
  - Priority: {High|Medium|Low}

- [x] **{Another issue}**
  - Line: {line number}
  - Fix: {what was done}
  - Priority: {High|Medium|Low}

## Issues Skipped

{List issues not addressed with reasons}

- [ ] **{Issue description}**
  - File: {path}
  - Reason: {Too complex | Ambiguous suggestion | Low priority | etc}
  - Priority: {High|Medium|Low}
  - Note: {Additional context on why skipped}

## Issues Failed

{List issues where fix was attempted but failed}

- [ ] **{Issue description}**
  - File: {path}
  - Attempted: {what was tried}
  - Error: {why it failed}
  - Priority: {High|Medium|Low}

## Files Modified

{List of absolute paths to files that were changed}

- /absolute/path/to/file1.ext - {count} fixes applied
- /absolute/path/to/file2.ext - {count} fixes applied

## Next Steps

1. Review changes with: git diff
2. Run tests to verify fixes didn't break functionality
3. Address skipped issues manually if needed
4. Re-run review to verify: /review-implementation
5. Commit when satisfied: /commit

## Notes

{Any additional context, patterns observed, or recommendations for
improving code quality going forward}
```

## Save Summary Document

1. Generate timestamp in format: YYYYMMDD-HHMMSS
2. Extract slug from review document name:
   - Example: review-impl-20260201-143000-auth-fixes.md
   - Extract: auth-fixes
3. Create filename: fixes-{timestamp}-{slug}.md
4. Ensure .jim/notes/ directory exists: `mkdir -p .jim/notes`
5. Save to: .jim/notes/fixes-{timestamp}-{slug}.md

## Return Value

Return concise summary to user:

```
Review Fixes Applied

Review Source: {path to review document}
Fixes Summary: {absolute path to fixes summary document}

Results:
  Addressed: {count} issues
  Skipped: {count} issues (complex or low priority)
  Failed: {count} issues

Files Modified: {count} files
{List files briefly}

Priority Level: {high|medium|low}

{If high priority issues remain unfixed:}
Remaining High Priority Issues: {count}
{List them briefly with file references}

Next Steps:
1. Review changes: git diff
2. Run tests to verify fixes
3. {If issues skipped: Address {count} skipped issues manually}
4. Re-run review: /review-implementation
5. Commit when ready: /commit

Fixes saved to: {path}
```

See README.md for usage examples.

## Guidelines

**Safe Fixes Only:**
- Only apply fixes you're confident won't break functionality
- When in doubt, skip the fix and flag for manual intervention
- Preserve existing code behavior and intent
- Don't try to be clever - follow review suggestions exactly

**Error Recovery:**
- If a fix fails, don't stop - continue with other fixes
- Log all failures for user review
- Never leave files in broken state (verify syntax)
- Track failures separately from skips

**User Control:**
- User should review all changes before committing
- Don't automatically commit fixes
- Provide clear summary of what was done
- Make it easy to see what changed (files modified list)

**Focus on Value:**
- Prioritize high-impact, low-risk fixes
- Don't waste time on ambiguous or complex issues
- Group fixes by file for efficient review
- Suggest re-running review to verify fixes worked

## Tips

- Read the entire review document to understand context
- Parse both Recommendations table and Areas for Improvement sections
- Some reviews may only have one or the other - handle both cases
- File paths in reviews should be absolute - use them directly
- Line numbers are hints, not exact positions (code may have changed)
- If suggestion has code example, use it as reference
- Track what you fix so user knows what still needs manual work
- Encourage user to re-review after fixes applied

## Notes

- This skill modifies files but does not commit changes
- Focuses on simple, safe fixes that follow review guidance
- Complex issues are flagged for manual intervention
- Works with both `/review` and `/review-implementation` output
- Different from `/refine` which does generic simplification
- This applies specific, targeted fixes from review feedback
- Always spawns via Task tool for clean context window
